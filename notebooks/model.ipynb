{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de98e739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corcasta/miniconda3/envs/farama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, DeepAR, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, MultivariateNormalDistributionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28de83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb775ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Male",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Female",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total_Amount",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product_Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price_per_Unit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Time_Unitless",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Week",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Window_Mean_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Window_Mean_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Window_Mean_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Window_Mean_7",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a3adbbfa-43ea-4103-aadb-ea99a460f76c",
       "rows": [
        [
         "0",
         "19.0",
         "0",
         "1",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "0",
         "2023",
         "1",
         "1",
         "81.25",
         "80.0",
         "70.83",
         "78.57"
        ],
        [
         "1",
         "19.0",
         "1",
         "0",
         "2",
         "50",
         "0",
         "Beauty",
         "25",
         "1",
         "2023",
         "1",
         "2",
         "81.25",
         "80.0",
         "70.83",
         "78.57"
        ],
        [
         "2",
         "34.0",
         "1",
         "2",
         "10",
         "250",
         "0",
         "Beauty",
         "25",
         "2",
         "2023",
         "1",
         "3",
         "81.25",
         "80.0",
         "70.83",
         "78.57"
        ],
        [
         "3",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "3",
         "2023",
         "1",
         "4",
         "81.25",
         "80.0",
         "70.83",
         "78.57"
        ],
        [
         "4",
         "23.0",
         "0",
         "1",
         "3",
         "75",
         "0",
         "Beauty",
         "25",
         "4",
         "2023",
         "1",
         "5",
         "93.75",
         "80.0",
         "70.83",
         "78.57"
        ],
        [
         "5",
         "43.0",
         "0",
         "1",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "5",
         "2023",
         "2",
         "6",
         "87.5",
         "80.0",
         "70.83",
         "78.57"
        ],
        [
         "6",
         "39.5",
         "2",
         "0",
         "5",
         "125",
         "0",
         "Beauty",
         "25",
         "6",
         "2023",
         "2",
         "7",
         "56.25",
         "95.0",
         "87.5",
         "78.57"
        ],
        [
         "7",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "7",
         "2023",
         "2",
         "8",
         "56.25",
         "45.0",
         "79.17",
         "75.0"
        ],
        [
         "8",
         "28.0",
         "0",
         "3",
         "5",
         "125",
         "0",
         "Beauty",
         "25",
         "8",
         "2023",
         "2",
         "9",
         "68.75",
         "70.0",
         "58.33",
         "85.71"
        ],
        [
         "9",
         "52.5",
         "0",
         "2",
         "8",
         "200",
         "0",
         "Beauty",
         "25",
         "9",
         "2023",
         "3",
         "10",
         "112.5",
         "95.0",
         "91.67",
         "78.57"
        ],
        [
         "10",
         "30.0",
         "0",
         "1",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "10",
         "2023",
         "3",
         "11",
         "87.5",
         "95.0",
         "83.33",
         "82.14"
        ],
        [
         "11",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "11",
         "2023",
         "3",
         "12",
         "87.5",
         "70.0",
         "79.17",
         "71.43"
        ],
        [
         "12",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "12",
         "2023",
         "3",
         "13",
         "56.25",
         "70.0",
         "58.33",
         "67.86"
        ],
        [
         "13",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "13",
         "2023",
         "4",
         "14",
         "6.25",
         "45.0",
         "58.33",
         "50.0"
        ],
        [
         "14",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "14",
         "2023",
         "4",
         "15",
         "0.0",
         "5.0",
         "37.5",
         "50.0"
        ],
        [
         "15",
         "62.0",
         "1",
         "0",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "15",
         "2023",
         "4",
         "16",
         "6.25",
         "5.0",
         "8.33",
         "35.71"
        ],
        [
         "16",
         "48.0",
         "1",
         "5",
         "15",
         "375",
         "0",
         "Beauty",
         "25",
         "16",
         "2023",
         "4",
         "17",
         "100.0",
         "80.0",
         "66.67",
         "60.71"
        ],
        [
         "17",
         "51.5",
         "0",
         "2",
         "5",
         "125",
         "0",
         "Beauty",
         "25",
         "17",
         "2023",
         "5",
         "18",
         "131.25",
         "105.0",
         "87.5",
         "75.0"
        ],
        [
         "18",
         "18.0",
         "1",
         "0",
         "3",
         "75",
         "0",
         "Beauty",
         "25",
         "18",
         "2023",
         "5",
         "19",
         "150.0",
         "120.0",
         "100.0",
         "85.71"
        ],
        [
         "19",
         "48.0",
         "1",
         "0",
         "4",
         "100",
         "0",
         "Beauty",
         "25",
         "19",
         "2023",
         "5",
         "20",
         "168.75",
         "140.0",
         "116.67",
         "100.0"
        ],
        [
         "20",
         "61.0",
         "1",
         "0",
         "2",
         "50",
         "0",
         "Beauty",
         "25",
         "20",
         "2023",
         "5",
         "21",
         "87.5",
         "145.0",
         "125.0",
         "107.14"
        ],
        [
         "21",
         "18.0",
         "0",
         "1",
         "3",
         "75",
         "0",
         "Beauty",
         "25",
         "21",
         "2023",
         "5",
         "22",
         "75.0",
         "85.0",
         "133.33",
         "117.86"
        ],
        [
         "22",
         "64.0",
         "1",
         "0",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "22",
         "2023",
         "6",
         "23",
         "62.5",
         "65.0",
         "75.0",
         "117.86"
        ],
        [
         "23",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "23",
         "2023",
         "6",
         "24",
         "37.5",
         "50.0",
         "54.17",
         "64.29"
        ],
        [
         "24",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "24",
         "2023",
         "6",
         "25",
         "25.0",
         "30.0",
         "41.67",
         "46.43"
        ],
        [
         "25",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "25",
         "2023",
         "6",
         "26",
         "6.25",
         "20.0",
         "25.0",
         "35.71"
        ],
        [
         "26",
         "61.0",
         "1",
         "0",
         "4",
         "100",
         "0",
         "Beauty",
         "25",
         "26",
         "2023",
         "7",
         "27",
         "25.0",
         "25.0",
         "33.33",
         "35.71"
        ],
        [
         "27",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "27",
         "2023",
         "7",
         "28",
         "25.0",
         "20.0",
         "20.83",
         "28.57"
        ],
        [
         "28",
         "51.0",
         "0",
         "1",
         "4",
         "100",
         "0",
         "Beauty",
         "25",
         "28",
         "2023",
         "7",
         "29",
         "50.0",
         "40.0",
         "33.33",
         "32.14"
        ],
        [
         "29",
         "22.0",
         "0",
         "1",
         "4",
         "100",
         "0",
         "Beauty",
         "25",
         "29",
         "2023",
         "7",
         "30",
         "75.0",
         "60.0",
         "50.0",
         "42.86"
        ],
        [
         "30",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "30",
         "2023",
         "7",
         "31",
         "50.0",
         "60.0",
         "50.0",
         "42.86"
        ],
        [
         "31",
         "38.0",
         "0",
         "1",
         "2",
         "50",
         "0",
         "Beauty",
         "25",
         "31",
         "2023",
         "8",
         "32",
         "62.5",
         "50.0",
         "58.33",
         "50.0"
        ],
        [
         "32",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "32",
         "2023",
         "8",
         "33",
         "37.5",
         "50.0",
         "41.67",
         "50.0"
        ],
        [
         "33",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "33",
         "2023",
         "8",
         "34",
         "12.5",
         "30.0",
         "41.67",
         "35.71"
        ],
        [
         "34",
         "47.5",
         "0",
         "4",
         "10",
         "250",
         "0",
         "Beauty",
         "25",
         "34",
         "2023",
         "8",
         "35",
         "75.0",
         "60.0",
         "66.67",
         "71.43"
        ],
        [
         "35",
         "54.0",
         "1",
         "0",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "35",
         "2023",
         "9",
         "36",
         "68.75",
         "65.0",
         "54.17",
         "60.71"
        ],
        [
         "36",
         "23.0",
         "1",
         "2",
         "8",
         "200",
         "0",
         "Beauty",
         "25",
         "36",
         "2023",
         "9",
         "37",
         "118.75",
         "95.0",
         "87.5",
         "75.0"
        ],
        [
         "37",
         "32.0",
         "1",
         "0",
         "2",
         "50",
         "0",
         "Beauty",
         "25",
         "37",
         "2023",
         "9",
         "38",
         "131.25",
         "105.0",
         "87.5",
         "82.14"
        ],
        [
         "38",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "38",
         "2023",
         "9",
         "39",
         "68.75",
         "105.0",
         "87.5",
         "75.0"
        ],
        [
         "39",
         "27.0",
         "2",
         "1",
         "8",
         "200",
         "0",
         "Beauty",
         "25",
         "39",
         "2023",
         "10",
         "40",
         "112.5",
         "95.0",
         "120.83",
         "103.57"
        ],
        [
         "40",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "40",
         "2023",
         "10",
         "41",
         "62.5",
         "90.0",
         "79.17",
         "103.57"
        ],
        [
         "41",
         "45.5",
         "0",
         "2",
         "4",
         "100",
         "0",
         "Beauty",
         "25",
         "41",
         "2023",
         "10",
         "42",
         "75.0",
         "70.0",
         "91.67",
         "82.14"
        ],
        [
         "42",
         "30.0",
         "3",
         "0",
         "8",
         "200",
         "0",
         "Beauty",
         "25",
         "42",
         "2023",
         "10",
         "43",
         "125.0",
         "100.0",
         "91.67",
         "107.14"
        ],
        [
         "43",
         "35.0",
         "2",
         "1",
         "10",
         "250",
         "0",
         "Beauty",
         "25",
         "43",
         "2023",
         "10",
         "44",
         "137.5",
         "150.0",
         "125.0",
         "114.29"
        ],
        [
         "44",
         "0.0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "Beauty",
         "25",
         "44",
         "2023",
         "11",
         "45",
         "137.5",
         "110.0",
         "125.0",
         "107.14"
        ],
        [
         "45",
         "57.0",
         "0",
         "1",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "45",
         "2023",
         "11",
         "46",
         "118.75",
         "115.0",
         "95.83",
         "110.71"
        ],
        [
         "46",
         "47.0",
         "0",
         "1",
         "4",
         "100",
         "0",
         "Beauty",
         "25",
         "46",
         "2023",
         "11",
         "47",
         "93.75",
         "115.0",
         "112.5",
         "96.43"
        ],
        [
         "47",
         "41.5",
         "1",
         "1",
         "6",
         "150",
         "0",
         "Beauty",
         "25",
         "47",
         "2023",
         "11",
         "48",
         "68.75",
         "105.0",
         "120.83",
         "117.86"
        ],
        [
         "48",
         "36.0",
         "1",
         "0",
         "1",
         "25",
         "0",
         "Beauty",
         "25",
         "48",
         "2023",
         "12",
         "49",
         "75.0",
         "60.0",
         "91.67",
         "107.14"
        ],
        [
         "49",
         "51.0",
         "0",
         "3",
         "7",
         "175",
         "0",
         "Beauty",
         "25",
         "49",
         "2023",
         "12",
         "50",
         "112.5",
         "95.0",
         "79.17",
         "103.57"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 776
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Price_per_Unit</th>\n",
       "      <th>Time_Unitless</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Window_Mean_4</th>\n",
       "      <th>Window_Mean_5</th>\n",
       "      <th>Window_Mean_6</th>\n",
       "      <th>Window_Mean_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81.25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.83</td>\n",
       "      <td>78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>81.25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.83</td>\n",
       "      <td>78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>81.25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.83</td>\n",
       "      <td>78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>81.25</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.83</td>\n",
       "      <td>78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>93.75</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.83</td>\n",
       "      <td>78.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3000</td>\n",
       "      <td>14</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>500</td>\n",
       "      <td>45</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1750.00</td>\n",
       "      <td>2142.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>500</td>\n",
       "      <td>46</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>1625.00</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1416.67</td>\n",
       "      <td>1500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1500</td>\n",
       "      <td>14</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>500</td>\n",
       "      <td>47</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>1125.00</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1333.33</td>\n",
       "      <td>1428.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6000</td>\n",
       "      <td>14</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>500</td>\n",
       "      <td>48</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>2625.00</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2333.33</td>\n",
       "      <td>2000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>14</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>500</td>\n",
       "      <td>49</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>2125.00</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>1916.67</td>\n",
       "      <td>2142.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Male  Female  Quantity  Total_Amount  Product_ID Product_Category  \\\n",
       "0    19.0     0       1         1            25           0           Beauty   \n",
       "1    19.0     1       0         2            50           0           Beauty   \n",
       "2    34.0     1       2        10           250           0           Beauty   \n",
       "3     0.0     0       0         0             0           0           Beauty   \n",
       "4    23.0     0       1         3            75           0           Beauty   \n",
       "..    ...   ...     ...       ...           ...         ...              ...   \n",
       "771  21.0     2       0         6          3000          14      Electronics   \n",
       "772   0.0     0       0         0             0          14      Electronics   \n",
       "773  55.0     0       1         3          1500          14      Electronics   \n",
       "774  50.0     4       1        12          6000          14      Electronics   \n",
       "775  63.0     1       0         2          1000          14      Electronics   \n",
       "\n",
       "     Price_per_Unit  Time_Unitless  Year  Month  Week  Window_Mean_4  \\\n",
       "0                25              0  2023      1     1          81.25   \n",
       "1                25              1  2023      1     2          81.25   \n",
       "2                25              2  2023      1     3          81.25   \n",
       "3                25              3  2023      1     4          81.25   \n",
       "4                25              4  2023      1     5          93.75   \n",
       "..              ...            ...   ...    ...   ...            ...   \n",
       "771             500             45  2023     11    47        1625.00   \n",
       "772             500             46  2023     11    48        1625.00   \n",
       "773             500             47  2023     12    49        1125.00   \n",
       "774             500             48  2023     12    50        2625.00   \n",
       "775             500             49  2023     12    51        2125.00   \n",
       "\n",
       "     Window_Mean_5  Window_Mean_6  Window_Mean_7  \n",
       "0             80.0          70.83          78.57  \n",
       "1             80.0          70.83          78.57  \n",
       "2             80.0          70.83          78.57  \n",
       "3             80.0          70.83          78.57  \n",
       "4             80.0          70.83          78.57  \n",
       "..             ...            ...            ...  \n",
       "771         1700.0        1750.00        2142.86  \n",
       "772         1300.0        1416.67        1500.00  \n",
       "773         1600.0        1333.33        1428.57  \n",
       "774         2100.0        2333.33        2000.00  \n",
       "775         2300.0        1916.67        2142.86  \n",
       "\n",
       "[776 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773549b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a027218",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = list(data.columns.drop([\"Product_ID\", \"Total_Amount\", \"Product_Category\", \"Time_Unitless\"]))\n",
    "feature_scalers = [None]*len(input_features)\n",
    "scalers_dict = dict(zip(input_features, feature_scalers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fe985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = data[data[\"Product_ID\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99bdecb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      25\n",
       "1      50\n",
       "2     250\n",
       "3       0\n",
       "4      75\n",
       "5      25\n",
       "6     125\n",
       "7       0\n",
       "8     125\n",
       "9     200\n",
       "10     25\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15     25\n",
       "16    375\n",
       "17    125\n",
       "18     75\n",
       "19    100\n",
       "20     50\n",
       "21     75\n",
       "22     25\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26    100\n",
       "27      0\n",
       "28    100\n",
       "29    100\n",
       "30      0\n",
       "31     50\n",
       "32      0\n",
       "33      0\n",
       "34    250\n",
       "35     25\n",
       "36    200\n",
       "37     50\n",
       "38      0\n",
       "39    200\n",
       "40      0\n",
       "41    100\n",
       "42    200\n",
       "43    250\n",
       "44      0\n",
       "45     25\n",
       "46    100\n",
       "47    150\n",
       "48     25\n",
       "49    175\n",
       "50     50\n",
       "51     25\n",
       "Name: Total_Amount, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.Total_Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3957e529",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 12\n",
    "max_prediction_length = 8\n",
    "\n",
    "shortest_series_len = data.groupby([\"Product_ID\"])[\"Time_Unitless\"].max().min()\n",
    "\n",
    "# This will indicate what will be the training dataset\n",
    "# And what will be the validation dataset\n",
    "training_cutoff = shortest_series_len - max_prediction_length\n",
    "\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(\n",
    "    data[lambda x: x.Time_Unitless <= training_cutoff],\n",
    "    time_idx=\"Time_Unitless\",\n",
    "    target=\"Total_Amount\",\n",
    "    target_normalizer=None,\n",
    "    categorical_encoders={\"Product_Category\": NaNLabelEncoder().fit(data.Product_Category)},\n",
    "    group_ids=[\"Product_ID\"],\n",
    "    static_categoricals=[\n",
    "        \"Product_Category\"\n",
    "    ],  # as we plan to forecast correlations, it is important to use series characteristics (e.g. a series identifier)\n",
    "    time_varying_unknown_reals=[\"Total_Amount\", *input_features],\n",
    "    min_encoder_length=12,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    scalers=scalers_dict,\n",
    ")\n",
    "\n",
    "valid_dataset = TimeSeriesDataSet.from_dataset(train_dataset, data, min_prediction_idx=training_cutoff + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5525addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = train_dataset.to_dataloader(batch_size=4, train=True)\n",
    "\n",
    "valid_dataloader = valid_dataset.to_dataloader(\n",
    "    train=False, batch_size=4, num_workers=0)#, batch_sampler=\"synchronized\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3631f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_idx': 'Time_Unitless',\n",
       " 'target': 'Total_Amount',\n",
       " 'group_ids': ['Product_ID'],\n",
       " 'weight': None,\n",
       " 'max_encoder_length': 12,\n",
       " 'min_encoder_length': 12,\n",
       " 'min_prediction_idx': 0,\n",
       " 'min_prediction_length': 8,\n",
       " 'max_prediction_length': 8,\n",
       " 'static_categoricals': ['Product_Category'],\n",
       " 'static_reals': None,\n",
       " 'time_varying_known_categoricals': None,\n",
       " 'time_varying_known_reals': None,\n",
       " 'time_varying_unknown_categoricals': None,\n",
       " 'time_varying_unknown_reals': ['Total_Amount',\n",
       "  'Age',\n",
       "  'Male',\n",
       "  'Female',\n",
       "  'Quantity',\n",
       "  'Price_per_Unit',\n",
       "  'Year',\n",
       "  'Month',\n",
       "  'Week',\n",
       "  'Window_Mean_4',\n",
       "  'Window_Mean_5',\n",
       "  'Window_Mean_6',\n",
       "  'Window_Mean_7'],\n",
       " 'variable_groups': None,\n",
       " 'constant_fill_strategy': None,\n",
       " 'allow_missing_timesteps': False,\n",
       " 'lags': None,\n",
       " 'add_relative_time_idx': False,\n",
       " 'add_target_scales': False,\n",
       " 'add_encoder_length': False,\n",
       " 'target_normalizer': TorchNormalizer(method='identity', center=True, transformation=None, method_kwargs=None),\n",
       " 'categorical_encoders': {'Product_Category': NaNLabelEncoder(add_nan=False, warn=True),\n",
       "  '__group_id__Product_ID': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       " 'scalers': {'Age': None,\n",
       "  'Male': None,\n",
       "  'Female': None,\n",
       "  'Quantity': None,\n",
       "  'Price_per_Unit': None,\n",
       "  'Year': None,\n",
       "  'Month': None,\n",
       "  'Week': None,\n",
       "  'Window_Mean_4': None,\n",
       "  'Window_Mean_5': None,\n",
       "  'Window_Mean_6': None,\n",
       "  'Window_Mean_7': None},\n",
       " 'randomize_length': None,\n",
       " 'predict_mode': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35da1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import Baseline, NHiTS, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, MQF2DistributionLoss, QuantileLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6583ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/corcasta/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/corcasta/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/corcasta/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(accelerator=\"cpu\", gradient_clip_val=0.1)\n",
    "net = NHiTS.from_dataset(\n",
    "    train_dataset,\n",
    "    learning_rate=3e-2,\n",
    "    weight_decay=1e-2,\n",
    "    loss=MQF2DistributionLoss(prediction_length=max_prediction_length),\n",
    "    backcast_loss_ratio=0.0,\n",
    "    hidden_size=64,\n",
    "    optimizer=\"AdamW\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa3a383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corcasta/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# find optimal learning rate\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuner\n\u001b[0;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-1\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggested learning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39msuggestion()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m fig \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mplot(show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, suggest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/tuner/tuning.py:180\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m lr_finder_callback\u001b[38;5;241m.\u001b[39m_early_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [lr_finder_callback] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lr_finder_callback]\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lr_finder_callback\u001b[38;5;241m.\u001b[39moptimal_lr\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    592\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:992\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[0;32m--> 992\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_fit_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    995\u001b[0m _log_hyperparams(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:227\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 227\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/callbacks/lr_finder.py:130\u001b[0m, in \u001b[0;36mLearningRateFinder.on_fit_start\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/callbacks/lr_finder.py:112\u001b[0m, in \u001b[0;36mLearningRateFinder.lr_find\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlr_find\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_lr \u001b[38;5;241m=\u001b[39m _lr_find(\n\u001b[1;32m    114\u001b[0m             trainer,\n\u001b[1;32m    115\u001b[0m             pl_module,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m             attr_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attr_name,\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_exit:\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/pytorch/utilities/seed.py:44\u001b[0m, in \u001b[0;36misolate_rng\u001b[0;34m(include_cuda)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misolate_rng\u001b[39m(include_cuda: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A context manager that resets the global random state on exit to what it was before entering.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    It supports isolating the states for PyTorch, Numpy, and Python built-in random number generators.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     states \u001b[38;5;241m=\u001b[39m \u001b[43m_collect_rng_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude_cuda\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     _set_rng_states(states)\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/lightning/fabric/utilities/seed.py:137\u001b[0m, in \u001b[0;36m_collect_rng_states\u001b[0;34m(include_cuda)\u001b[0m\n\u001b[1;32m    135\u001b[0m     states[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mget_state()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_cuda:\n\u001b[0;32m--> 137\u001b[0m     states[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.cuda\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rng_state_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m states\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/torch/cuda/random.py:47\u001b[0m, in \u001b[0;36mget_rng_state_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_rng_state_all\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tensor]:\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of ByteTensor representing the random number states of all devices.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     results \u001b[38;5;241m=\u001b[39m [get_rng_state(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count())]\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/torch/cuda/random.py:47\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_rng_state_all\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tensor]:\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of ByteTensor representing the random number states of all devices.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\u001b[43mget_rng_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count())]\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/torch/cuda/random.py:33\u001b[0m, in \u001b[0;36mget_rng_state\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_rng_state\u001b[39m(device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the random number generator state of the specified GPU as a ByteTensor.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        This function eagerly initializes CUDA.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     35\u001b[0m         device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/farama/lib/python3.10/site-packages/torch/cuda/__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "    net, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader, min_lr=1e-5, max_lr=1e-1\n",
    ")\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "net.hparams.learning_rate = res.suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a932fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b35ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47130a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47deedcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
